{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "import os\nimport subprocess\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql.window import Window\n\nimport shutil\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\npd.set_option(\"max_colwidth\", 100)\nspark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)\n\nfrom google.cloud import storage"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Collecting pycountry\n  Downloading pycountry-20.7.3.tar.gz (10.1 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10.1 MB 5.3 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pycountry\n  Building wheel for pycountry (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pycountry: filename=pycountry-20.7.3-py2.py3-none-any.whl size=10746865 sha256=f4a761e31ad26c3164e524375cce3ba665e5689551116e6fe415be3d1371ec4e\n  Stored in directory: /root/.cache/pip/wheels/09/eb/0d/4ee773c6a4aadc2a43cb5c1d07f268f13c4cdc0eec88e7c1ef\nSuccessfully built pycountry\nInstalling collected packages: pycountry\nSuccessfully installed pycountry-20.7.3\nCollecting pycountry_convert\n  Downloading pycountry_convert-0.7.2-py3-none-any.whl (13 kB)\nCollecting pytest-cov>=2.5.1\n  Downloading pytest_cov-3.0.0-py3-none-any.whl (20 kB)\nRequirement already satisfied: wheel>=0.30.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from pycountry_convert) (0.35.1)\nCollecting repoze.lru>=0.7\n  Downloading repoze.lru-0.7-py3-none-any.whl (10 kB)\nCollecting pytest-mock>=1.6.3\n  Downloading pytest_mock-3.6.1-py3-none-any.whl (12 kB)\nRequirement already satisfied: pycountry>=16.11.27.1 in /opt/conda/miniconda3/lib/python3.8/site-packages (from pycountry_convert) (20.7.3)\nCollecting pprintpp>=0.3.0\n  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\nCollecting pytest>=3.4.0\n  Downloading pytest-6.2.5-py3-none-any.whl (280 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 280 kB 8.1 MB/s eta 0:00:01\n\u001b[?25hCollecting coverage[toml]>=5.2.1\n  Downloading coverage-6.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (217 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 217 kB 59.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/miniconda3/lib/python3.8/site-packages (from pytest>=3.4.0->pycountry_convert) (0.13.1)\nRequirement already satisfied: toml in /opt/conda/miniconda3/lib/python3.8/site-packages (from pytest>=3.4.0->pycountry_convert) (0.10.1)\nRequirement already satisfied: packaging in /opt/conda/miniconda3/lib/python3.8/site-packages (from pytest>=3.4.0->pycountry_convert) (20.4)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from pytest>=3.4.0->pycountry_convert) (20.2.0)\nCollecting iniconfig\n  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\nCollecting py>=1.8.2\n  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 98 kB 12.5 MB/s eta 0:00:01\n\u001b[?25hCollecting tomli; extra == \"toml\"\n  Downloading tomli-1.2.2-py3-none-any.whl (12 kB)\nRequirement already satisfied: six in /opt/conda/miniconda3/lib/python3.8/site-packages (from packaging->pytest>=3.4.0->pycountry_convert) (1.15.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/miniconda3/lib/python3.8/site-packages (from packaging->pytest>=3.4.0->pycountry_convert) (2.4.7)\nInstalling collected packages: tomli, coverage, iniconfig, py, pytest, pytest-cov, repoze.lru, pytest-mock, pprintpp, pycountry-convert\nSuccessfully installed coverage-6.2 iniconfig-1.1.1 pprintpp-0.4.0 py-1.11.0 pycountry-convert-0.7.2 pytest-6.2.5 pytest-cov-3.0.0 pytest-mock-3.6.1 repoze.lru-0.7 tomli-1.2.2\n"}], "source": "# ! pip install pycountry\n# ! pip install pycountry_convert\n\nimport pycountry as pyc\nimport pycountry_convert as pyc_c"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "CPU times: user 1.77 ms, sys: 3.69 ms, total: 5.46 ms\nWall time: 6.54 s\n"}], "source": "%%time\n\npath = 'gs://msca-bdp-students-bucket/shared_data/kaihayden/final1'\n\ntweets_df = spark.read.parquet(path)"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": "# tweets_df.columns"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": "tweets_original = tweets_df.filter(col('is_original')==1)"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": "# tweets_original.count()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "-RECORD 0--------------------\n created_at        | 0       \n dt_date           | 0       \n dt_datehour       | 0       \n dt_day            | 0       \n dt_hour           | 0       \n dt_month          | 0       \n dt_year           | 0       \n ext_qt_user_id    | 2739456 \n ext_rp_user_id    | 2648070 \n ext_rt_id         | 2739456 \n ext_rt_user_id    | 2739456 \n is_original       | 0       \n reply_count       | 0       \n twt_country       | 2692688 \n twt_hashtags      | 0       \n twt_id            | 0       \n twt_importance    | 0       \n twt_likes         | 0       \n twt_location      | 2692688 \n twt_location_full | 2692688 \n twt_location_type | 2692688 \n twt_quote_count   | 0       \n twt_reply_count   | 0       \n twt_retwt_count   | 0       \n twt_text          | 0       \n usr_desc          | 278311  \n usr_followers     | 0       \n usr_id            | 0       \n usr_location      | 739986  \n usr_name          | 0       \n usr_tweet_count   | 0       \n usr_verified      | 0       \n\n"}], "source": "# tweets_original.select([count(when(col(c).isNull(), c)).alias(c) for c in tweets_original.columns]).show(vertical=True)"}, {"cell_type": "code", "execution_count": 33, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "-RECORD 0---------------------\n created_at        | 0        \n dt_date           | 0        \n dt_datehour       | 0        \n dt_day            | 0        \n dt_hour           | 0        \n dt_month          | 0        \n dt_year           | 0        \n ext_qt_user_id    | 19016605 \n ext_rp_user_id    | 20700808 \n ext_rt_id         | 7350818  \n ext_rt_user_id    | 7350818  \n is_original       | 0        \n reply_count       | 0        \n twt_country       | 23779768 \n twt_hashtags      | 0        \n twt_id            | 0        \n twt_importance    | 0        \n twt_likes         | 0        \n twt_location      | 23779768 \n twt_location_full | 23779768 \n twt_location_type | 23779768 \n twt_quote_count   | 0        \n twt_reply_count   | 0        \n twt_retwt_count   | 0        \n twt_text          | 0        \n usr_desc          | 4470803  \n usr_followers     | 0        \n usr_id            | 0        \n usr_location      | 9017922  \n usr_name          | 0        \n usr_tweet_count   | 0        \n usr_verified      | 0        \n\n"}], "source": "tweets_df.select([count(when(col(c).isNull(), c)).alias(c) for c in tweets_original.columns]).show(vertical=True)"}, {"cell_type": "markdown", "metadata": {}, "source": "### only about 47000 original tweets with locations, we'll try to extract continents from locations"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": "country_name = [i.name for i in pyc.countries]\ncountry_3 = [i.alpha_3 for i in pyc.countries]\ncountry_2 = [i.alpha_2 for i in pyc.countries]"}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": "def cont_name(a):\n    try:\n        return pyc_c.country_alpha2_to_continent_code(pyc_c.country_name_to_country_alpha2(a))\n    except:\n        return None\ndef cont_3(a):\n    try:\n        return pyc_c.country_alpha2_to_continent_code(pyc_c.country_alpha3_to_country_alpha2(a))\n    except:\n        return None\ndef cont_2(a):\n    try:\n        return pyc_c.country_alpha2_to_continent_code(a)\n    except:\n        return None\n\n# 'NA','AS','AF','EU','SA','OC'"}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": "states = [ 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n           'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n           'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n           'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n           'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']\nstates = [', '+ s for s in states]\n\nna_full = [country for country in country_name if cont_name(country) == 'NA']\nna_full.extend(['America','Curacao','Saint Martin','Virgin Islands'])\nas_full = [country for country in country_name if cont_name(country) == 'AS']\nas_full.extend(['Taiwan','Hong Kong','Vietnam','Korea','Laos','Macau','Iran'])\naf_full = [country for country in country_name if cont_name(country) == 'AF']\neu_full = [country for country in country_name if cont_name(country) == 'EU']\neu_full.extend(['England','Scotland','Ireland','Wales'])\nsa_full = [country for country in country_name if cont_name(country) == 'SA']\nsa_full.extend(['Venezuela','Bolivia','Falkland'])\noc_full = [country for country in country_name if cont_name(country) == 'OC']\noc_full.extend(['Micronesia'])\n\nna_full1 = [', '+ c for c in na_full]\nas_full1 = [', '+ c for c in as_full]\naf_full1 = [', '+ c for c in af_full]\neu_full1 = [', '+ c for c in eu_full]\nsa_full1 = [', '+ c for c in sa_full]\noc_full1 = [', '+ c for c in oc_full]\n\nna_3 = [country for country in country_3 if cont_3(country) == 'NA']\nna_3.extend(states)\nas_3 = [country for country in country_3 if cont_3(country) == 'AS']\naf_3 = [country for country in country_3 if cont_3(country) == 'AF']\neu_3 = [country for country in country_3 if cont_3(country) == 'EU']\neu_3.extend(['ENG','SCO','WAL','IRE'])\nsa_3 = [country for country in country_3 if cont_3(country) == 'SA']\noc_3 = [country for country in country_3 if cont_3(country) == 'OC']\n\nna_2 = [country for country in country_2 if cont_2(country) == 'NA']\nna_2.remove('DM')\nas_2 = [country for country in country_2 if cont_2(country) == 'AS']\nas_2.remove('IN')\nas_2.remove('LA')\naf_2 = [country for country in country_2 if cont_2(country) == 'AF']\neu_2 = [country for country in country_2 if cont_2(country) == 'EU']\neu_2.extend(['UK'])\nsa_2 = [country for country in country_2 if cont_2(country) == 'SA']\noc_2 = [country for country in country_2 if cont_2(country) == 'OC']"}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": "tweets_usr_locations = tweets_df.select([\"usr_id\",\"usr_location\"]).na.drop().dropDuplicates()"}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": "# tweets_usr_locations.show(5)"}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": "tweets_na = tweets_usr_locations.withColumn('loc0', when(lower(col(\"usr_location\")).rlike(\"|\".join([\"(\" + kw.lower() + \")\" for kw in na_full1])),lit(4)).otherwise(lit(0)))\\\n                                .withColumn('loc1', when(col(\"usr_location\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in na_3])),lit(4)).otherwise(lit(0)))\\\n                                .withColumn('loc2', when(lower(col(\"usr_location\")).rlike(\"|\".join([\"(\" + kw.lower() + \")\" for kw in na_full])),lit(3)).otherwise(lit(0)))\\\n                                .withColumn('loc3', when(col(\"usr_location\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in na_2])),lit(2)).otherwise(lit(0)))\\\n                                .withColumn('continent',lit('NA'))\n    \ntweets_na = tweets_na.withColumn(\"score\", col('loc0')+col('loc1')+col('loc2')+col('loc3'))\n\ntweets_na = tweets_na.select('usr_id','usr_location','score','continent')\\\n                     .filter(col('score').isNotNull()).orderBy('score',ascending=False)"}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": "tweets_as = tweets_usr_locations.withColumn('loc0', when(lower(col(\"usr_location\")).rlike(\"|\".join([\"(\" + kw.lower() + \")\" for kw in as_full1])),lit(4)).otherwise(lit(0)))\\\n                                .withColumn('loc1', when(col(\"usr_location\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in as_3])),lit(4)).otherwise(lit(0)))\\\n                                .withColumn('loc2', when(lower(col(\"usr_location\")).rlike(\"|\".join([\"(\" + kw.lower() + \")\" for kw in as_full])),lit(3)).otherwise(lit(0)))\\\n                                .withColumn('loc3', when(col(\"usr_location\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in as_2])),lit(2)).otherwise(lit(0)))\\\n                                .withColumn('continent',lit('AS'))\n    \ntweets_as = tweets_as.withColumn(\"score\", col('loc0')+col('loc1')+col('loc2')+col('loc3'))\n\ntweets_as = tweets_as.select('usr_id','usr_location','score','continent')\\\n                     .filter(col('score').isNotNull()).orderBy('score',ascending=False)"}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": "tweets_af = tweets_usr_locations.withColumn('loc0', when(lower(col(\"usr_location\")).rlike(\"|\".join([\"(\" + kw.lower() + \")\" for kw in af_full1])),lit(4)).otherwise(lit(0)))\\\n                                .withColumn('loc1', when(col(\"usr_location\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in af_3])),lit(4)).otherwise(lit(0)))\\\n                                .withColumn('loc2', when(lower(col(\"usr_location\")).rlike(\"|\".join([\"(\" + kw.lower() + \")\" for kw in af_full])),lit(3)).otherwise(lit(0)))\\\n                                .withColumn('loc3', when(col(\"usr_location\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in af_2])),lit(2)).otherwise(lit(0)))\\\n                                .withColumn('continent',lit('AF'))\n    \ntweets_af = tweets_af.withColumn(\"score\", col('loc0')+col('loc1')+col('loc2')+col('loc3'))\n\ntweets_af = tweets_af.select('usr_id','usr_location','score','continent')\\\n                     .filter(col('score').isNotNull()).orderBy('score',ascending=False)"}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": "tweets_eu = tweets_usr_locations.withColumn('loc0', when(lower(col(\"usr_location\")).rlike(\"|\".join([\"(\" + kw.lower() + \")\" for kw in eu_full1])),lit(4)).otherwise(lit(0)))\\\n                                .withColumn('loc1', when(col(\"usr_location\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in eu_3])),lit(4)).otherwise(lit(0)))\\\n                                .withColumn('loc2', when(lower(col(\"usr_location\")).rlike(\"|\".join([\"(\" + kw.lower() + \")\" for kw in eu_full])),lit(3)).otherwise(lit(0)))\\\n                                .withColumn('loc3', when(col(\"usr_location\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in eu_2])),lit(2)).otherwise(lit(0)))\\\n                                .withColumn('continent',lit('EU'))\n    \ntweets_eu = tweets_eu.withColumn(\"score\", col('loc0')+col('loc1')+col('loc2')+col('loc3'))\n\ntweets_eu = tweets_eu.select('usr_id','usr_location','score','continent')\\\n                     .filter(col('score').isNotNull()).orderBy('score',ascending=False)"}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": "tweets_sa = tweets_usr_locations.withColumn('loc0', when(lower(col(\"usr_location\")).rlike(\"|\".join([\"(\" + kw.lower() + \")\" for kw in sa_full1])),lit(4)).otherwise(lit(0)))\\\n                                .withColumn('loc1', when(col(\"usr_location\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in sa_3])),lit(4)).otherwise(lit(0)))\\\n                                .withColumn('loc2', when(lower(col(\"usr_location\")).rlike(\"|\".join([\"(\" + kw.lower() + \")\" for kw in sa_full])),lit(3)).otherwise(lit(0)))\\\n                                .withColumn('loc3', when(col(\"usr_location\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in sa_2])),lit(2)).otherwise(lit(0)))\\\n                                .withColumn('continent',lit('SA'))\n    \ntweets_sa = tweets_sa.withColumn(\"score\", col('loc0')+col('loc1')+col('loc2')+col('loc3'))\n\ntweets_sa = tweets_sa.select('usr_id','usr_location','score','continent')\\\n                     .filter(col('score').isNotNull()).orderBy('score',ascending=False)"}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": "tweets_oc = tweets_usr_locations.withColumn('loc0', when(lower(col(\"usr_location\")).rlike(\"|\".join([\"(\" + kw.lower() + \")\" for kw in oc_full1])),lit(4)).otherwise(lit(0)))\\\n                                .withColumn('loc1', when(col(\"usr_location\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in oc_3])),lit(4)).otherwise(lit(0)))\\\n                                .withColumn('loc2', when(lower(col(\"usr_location\")).rlike(\"|\".join([\"(\" + kw.lower() + \")\" for kw in oc_full])),lit(3)).otherwise(lit(0)))\\\n                                .withColumn('loc3', when(col(\"usr_location\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in oc_2])),lit(2)).otherwise(lit(0)))\\\n                                .withColumn('continent',lit('OC'))\n    \ntweets_oc = tweets_oc.withColumn(\"score\", col('loc0')+col('loc1')+col('loc2')+col('loc3'))\n\ntweets_oc = tweets_oc.select('usr_id','usr_location','score','continent')\\\n                     .filter(col('score').isNotNull()).orderBy('score',ascending=False)"}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": "tweets_loc = tweets_na.union(tweets_as)\\\n                      .union(tweets_af)\\\n                      .union(tweets_eu)\\\n                      .union(tweets_oc)\\\n                      .union(tweets_sa)"}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": "tweets_score1 = tweets_loc.orderBy(col('score'),ascending=False)\\\n                          .groupby(['usr_id','usr_location','score']).agg(sum(lit(1)).alias('freq'))\n\ntweets_score1 = tweets_score1.filter(col('freq')==1).drop('freq')"}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [], "source": "w = Window.partitionBy(\"usr_id\").orderBy(col(\"score\").desc())\n\ntweets_score2 = tweets_loc.withColumn(\"row\",row_number().over(w))\\\n                          .filter(col(\"row\") == 1).drop(\"row\")\\\n                          .filter(col('score') > 0)"}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [], "source": "usr_continent = tweets_score1.join(tweets_score2, [\"usr_id\",\"usr_location\",\"score\"],\"inner\")\\\n                             .drop('score')"}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [], "source": "# %%time\n\n# usr_continent.show(50,False)"}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [], "source": "tweets_df_cont = tweets_df.join(usr_continent, ['usr_id','usr_location'], 'left')\n\ntweets_df_cont = tweets_df_cont.withColumn(\"twt_continent1\", when(col(\"twt_country\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in na_2])),lit('NA')).\\\n                                                             when(col(\"twt_country\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in as_2])),lit('AS')).\\\n                                                             when(col(\"twt_country\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in af_2])),lit('AF')).\\\n                                                             when(col(\"twt_country\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in eu_2])),lit('EU')).\\\n                                                             when(col(\"twt_country\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in sa_2])),lit('SA')).\\\n                                                             when(col(\"twt_country\").rlike(\"|\".join([\"(\" + kw + \")\" for kw in oc_2])),lit('OC')))\n\ntweets_df_cont = tweets_df_cont.withColumn(\"twt_continent\", when(col(\"twt_continent1\").isNotNull(),col(\"twt_continent1\")).otherwise(col(\"continent\")))\\\n                               .drop('continent','twt_continent1','created_at','reply_count','twt_country','twt_location','twt_location_full','twt_location_type')\n\ntweets_df_cont = tweets_df_cont.select(sorted(tweets_df_cont.columns))"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "-RECORD 0------------------\n dt_date         | 0       \n dt_datehour     | 0       \n dt_day          | 0       \n dt_hour         | 0       \n dt_month        | 0       \n dt_year         | 0       \n ext_qt_user_id  | 2739456 \n ext_rp_user_id  | 2648070 \n ext_rt_id       | 2739456 \n ext_rt_user_id  | 2739456 \n is_original     | 0       \n twt_continent   | 1574108 \n twt_hashtags    | 0       \n twt_id          | 0       \n twt_importance  | 0       \n twt_likes       | 0       \n twt_quote_count | 0       \n twt_reply_count | 0       \n twt_retwt_count | 0       \n twt_text        | 0       \n usr_desc        | 278311  \n usr_followers   | 0       \n usr_id          | 0       \n usr_location    | 739986  \n usr_name        | 0       \n usr_tweet_count | 0       \n usr_verified    | 0       \n\n"}], "source": "tweets_df_cont_o = tweets_df_cont.filter(col('is_original')==1)\ntweets_df_cont_o.select([count(when(col(c).isNull(), c)).alias(c) for c in tweets_df_cont_o.columns]).show(vertical=True)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "-RECORD 0-------------------\n dt_date         | 0        \n dt_datehour     | 0        \n dt_day          | 0        \n dt_hour         | 0        \n dt_month        | 0        \n dt_year         | 0        \n ext_qt_user_id  | 19016605 \n ext_rp_user_id  | 20700808 \n ext_rt_id       | 7350818  \n ext_rt_user_id  | 7350818  \n is_original     | 0        \n twt_continent   | 15603656 \n twt_hashtags    | 0        \n twt_id          | 0        \n twt_importance  | 0        \n twt_likes       | 0        \n twt_quote_count | 0        \n twt_reply_count | 0        \n twt_retwt_count | 0        \n twt_text        | 0        \n usr_desc        | 4470803  \n usr_followers   | 0        \n usr_id          | 0        \n usr_location    | 9017922  \n usr_name        | 0        \n usr_tweet_count | 0        \n usr_verified    | 0        \n\n"}], "source": "tweets_df_cont.select([count(when(col(c).isNull(), c)).alias(c) for c in tweets_df_cont.columns]).show(vertical=True)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": "23913387"}, "execution_count": 27, "metadata": {}, "output_type": "execute_result"}], "source": "tweets_df_cont.count()"}, {"cell_type": "markdown", "metadata": {}, "source": "total rows = 23913387\n\ntotal continent null = 15603656"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "tweets_df_cont = tweets_df_cont.select(sorted(tweets_df_cont.columns))"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "CPU times: user 483 ms, sys: 9.66 ms, total: 492 ms\nWall time: 7.17 s\n"}], "source": "%%time\n\n# Delete folder from COS bucket\ndef delete_folder(bucket_name, folder_name):\n    gcs_client = storage.Client()\n    bucket = gcs_client.bucket(bucket_name)\n    blobs = list(bucket.list_blobs(prefix=folder_name))\n\n    for blob in blobs:\n        blob.delete()\n\ndelete_folder('msca-bdp-students-bucket', 'shared_data/kaihayden/final2')"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "CPU times: user 46.2 ms, sys: 20 ms, total: 66.2 ms\nWall time: 6min 6s\n"}], "source": "%%time\n\ntweets_df_cont.write.format(\"parquet\")\\\n              .mode('overwrite')\\\n              .save('gs://msca-bdp-students-bucket/shared_data/kaihayden/final2')"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": "['dt_date',\n 'dt_datehour',\n 'dt_day',\n 'dt_hour',\n 'dt_month',\n 'dt_year',\n 'ext_qt_user_id',\n 'ext_rp_user_id',\n 'ext_rt_id',\n 'ext_rt_user_id',\n 'is_original',\n 'twt_continent',\n 'twt_hashtags',\n 'twt_id',\n 'twt_importance',\n 'twt_likes',\n 'twt_quote_count',\n 'twt_reply_count',\n 'twt_retwt_count',\n 'twt_text',\n 'usr_desc',\n 'usr_followers',\n 'usr_id',\n 'usr_location',\n 'usr_name',\n 'usr_tweet_count',\n 'usr_verified']"}, "execution_count": 31, "metadata": {}, "output_type": "execute_result"}], "source": "# tweets_df_cont.columns"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}